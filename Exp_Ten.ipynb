{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries and modules\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten, Conv2D, MaxPool2D #Max pooling operation for 2D spatial data.\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a model named build_model\n",
    "def build_model():\n",
    "    # input layers with channel 1 for 28x28 grayscale image\n",
    "\tinputs = Input((28, 28, 1))\n",
    "    # a convolution layer with 10 kernel of size 3x3, strides size 2x2 and valid padding means no padding used here\n",
    "\tx = Conv2D(10, (3,3), strides=(2,2), padding = 'valid')(inputs)\n",
    "    # another convolution layer with 4 kernel of size 2x2, strides size 2x2 and valid padding means no padding used here\n",
    "\tx = Conv2D(4, (2,2), strides=(2,2), padding = 'valid')(x)\n",
    "    # Flatten layer by flattening the previous layer\n",
    "\tx = Flatten()(x)\n",
    "    # Dense layer with 100 neuron\n",
    "\tx = Dense(100, activation = 'relu')(x)\n",
    "    # output layer with 10 class\n",
    "\toutputs = Dense(10, activation='softmax')(x)\n",
    "    # model feeded with inputs and outputs\n",
    "\tmodel = Model(inputs, outputs)\n",
    "    # for model summary\n",
    "\tmodel.summary()\n",
    "    # for determining the loss of model\n",
    "\tmodel.compile(loss = 'mse', optimizer='rmsprop')\n",
    "    \n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\tmodel = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\tmain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inputs = Input((28, 28, 1))\n",
    "x = Conv2D(10, (3,3), strides=(2,2), padding = 'valid')(inputs)\n",
    "x = Conv2D(4, (2,2), strides=(2,2), padding = 'valid')(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(100, activation = 'relu')(x)\n",
    "outputs = Dense(10, activation='softmax')(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VALID Padding: it means no padding and it assumes that all the dimensions are valid so that the input image gets fully covered by a filter and the stride specified by you.\n",
    "### The padding type is called SAME because the output size is the same as the input size(when stride=1). Using 'SAME' ensures that the filter is applied to all the elements of the input. Normally, padding is set to \"SAME\" while training the model. Output size is mathematically convenient for further computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 13, 13, 10)        100       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 6, 6, 4)           164       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 144)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               14500     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,774\n",
      "Trainable params: 15,774\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mse', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of parameters in Keras Conv2D layer is calculated using the following equation:\n",
    "\n",
    "#### number_parameters = out_channels * (in_channels * kernel_h * kernel_w + 1)  # 1 for bias\n",
    "#### here, in_channels=1, out_channels=10,kernel_h=3,kernel_w=3 i.e 100\n",
    "#### out_channels=4,inchannels=10,kernel_h=2,kernel_w=2 i.e 164\n",
    "#### (144+1=145*100=14500, 100+1=101*10=1010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
