{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import EarlyStopping, History\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DIR = '/home/bibrity/DeepLearning/'\n",
    "DIR ='C:/Users/SRTINNI/Desktop/Ai/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\t# Prepare data sets\n",
    "\ttrainX, trainY, testX, testY = prepare_data()\n",
    "\t\n",
    "\t# Build a model\n",
    "\tmodel = build_model()\n",
    "\n",
    "\t# Train the model\n",
    "\tcallbackList = [EarlyStopping(monitor = 'val_loss', patience = 10), History()]\n",
    "\thistory = model.fit(trainX, trainY, epochs = 300, batch_size = 16, callbacks = callbackList, validation_split = 0.2)\n",
    "\tplot_loss(history)\n",
    "\n",
    "\t# Check what the model predicts.\n",
    "\tpredictY = model.predict(testX)\n",
    "\tfor i in range(10):\n",
    "\t\ty = np.argmax(testY[i])\n",
    "\t\tpY = np.argmax(predictY[i])\n",
    "\t\tprint('Original Y: {}, Predicted Y: {}'.format(y, pY))\n",
    "\t\t\n",
    "\t# Estimate the performance of the NN.\t\n",
    "\tmodel.compile(metrics = 'accuracy')\n",
    "\tmodel.evaluate(testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "\tinputs = Input((28, 28))\n",
    "\tx = Flatten()(inputs)\n",
    "\tx = Dense(32, activation = 'sigmoid')(x)\n",
    "\tx = Dense(16, activation = 'sigmoid')(x)\n",
    "\toutputs = Dense(10)(x)\n",
    "\t\n",
    "\tmodel = Model(inputs, outputs)\n",
    "\tmodel.summary()\n",
    "\t\n",
    "\tmodel.compile(loss = 'mse', optimizer = RMSprop(learning_rate = 0.001))\n",
    "\t\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "\t# Load data\n",
    "\t(trainX, trainY), (testX, testY) = mnist.load_data()\n",
    "\t#plot_digits(trainX[:9], trainY[:9])\n",
    "\tprint(trainX.shape, trainY.shape, testX.shape, testY.shape)\n",
    "\n",
    "\t# Convert numeric digit labels into one-hot vectors.\n",
    "\t# 0: 1 0 0 0 0 0 0 0 0\n",
    "\t# 1: 0 1 0 0 0 0 0 0 0\n",
    "\t# 2: 0 0 1 0 0 0 0 0 0\t\n",
    "\tprint('Labels: {}, DataType: {}'.format(trainY[:10], trainY[:10].dtype))\n",
    "\tclassN = 10\n",
    "\ttrainY = to_categorical(trainY, classN)\n",
    "\ttestY = to_categorical(testY, classN)\n",
    "\tprint('Labels: {}, DataType: {}'.format(trainY[:10], trainY[:10].dtype))\n",
    "\t\n",
    "\t# To convert pixel values from 0-255 into 0-1.\t\n",
    "\tprint('DataType: {}, Max: {}, Min: {}'.format(trainX.dtype, trainX.max(), trainX.min()))\n",
    "\ttrainX = trainX.astype(np.float32)\n",
    "\ttestX = testX.astype(np.float32)\n",
    "\ttrainX /= 255\n",
    "\ttestX /= 255\t\n",
    "\tprint('DataType: {}, Max: {}, Min: {}'.format(trainX.dtype, trainX.max(), trainX.min()))\n",
    "\t\t\n",
    "\treturn trainX, trainY, testX, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_digits(x, y):\n",
    "\tn = len(y)\n",
    "\tplt.figure(figsize = (20,20))\n",
    "\tfor i in range(n):\n",
    "\t\tplt.subplot(3, 3, i+1)\n",
    "\t\tplt.imshow(x[i], cmap = 'gray')\n",
    "\t\tplt.title(y[i])\n",
    "\tplt.show()\n",
    "\tplt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss(history):\n",
    "\tloss = history.history['loss']\n",
    "\tvalLoss = history.history['val_loss']\n",
    "\tepochs = range(1, len(loss) + 1)\n",
    "\n",
    "\tplt.figure(figsize = (20, 20))\n",
    "\tplt.rcParams['font.size'] = '20'\n",
    "\tplt.plot(epochs, loss, 'bo-', label = 'Training loss')\n",
    "\tplt.plot(epochs, valLoss, 'k*-', label = 'Validation loss')\n",
    "\tplt.title('Training and validation loss')\n",
    "\tplt.legend()\n",
    "\tfigPath = DIR +'__results___7_0.png'\n",
    "\t#figPath = DIR + 'Digit_Recognizer_TrainvsVal_Loss.png'\n",
    "    \n",
    "\tplt.savefig(figPath)\n",
    "\tplt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n",
      "Labels: [5 0 4 1 9 2 1 3 1 4], DataType: uint8\n",
      "Labels: [[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]], DataType: float32\n",
      "DataType: uint8, Max: 255, Min: 0\n",
      "DataType: float32, Max: 1.0, Min: 0.0\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28)]          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                25120     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                170       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,818\n",
      "Trainable params: 25,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/300\n",
      "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0330 - val_loss: 0.0189\n",
      "Epoch 2/300\n",
      "3000/3000 [==============================] - 5s 2ms/step - loss: 0.0172 - val_loss: 0.0146\n",
      "Epoch 3/300\n",
      "3000/3000 [==============================] - 5s 2ms/step - loss: 0.0144 - val_loss: 0.0130\n",
      "Epoch 4/300\n",
      "3000/3000 [==============================] - 5s 2ms/step - loss: 0.0130 - val_loss: 0.0121\n",
      "Epoch 5/300\n",
      "3000/3000 [==============================] - 5s 2ms/step - loss: 0.0120 - val_loss: 0.0119\n",
      "Epoch 6/300\n",
      "3000/3000 [==============================] - 5s 2ms/step - loss: 0.0113 - val_loss: 0.0108\n",
      "Epoch 7/300\n",
      "3000/3000 [==============================] - 5s 2ms/step - loss: 0.0107 - val_loss: 0.0104\n",
      "Epoch 8/300\n",
      "3000/3000 [==============================] - 5s 2ms/step - loss: 0.0102 - val_loss: 0.0103\n",
      "Epoch 9/300\n",
      "3000/3000 [==============================] - 5s 2ms/step - loss: 0.0099 - val_loss: 0.0098\n",
      "Epoch 10/300\n",
      "3000/3000 [==============================] - 5s 2ms/step - loss: 0.0095 - val_loss: 0.0095\n",
      "Epoch 11/300\n",
      "3000/3000 [==============================] - 6s 2ms/step - loss: 0.0092 - val_loss: 0.0093\n",
      "Epoch 12/300\n",
      "3000/3000 [==============================] - 5s 2ms/step - loss: 0.0090 - val_loss: 0.0091\n",
      "Epoch 13/300\n",
      "3000/3000 [==============================] - 5s 2ms/step - loss: 0.0088 - val_loss: 0.0093\n",
      "Epoch 14/300\n",
      "1784/3000 [================>.............] - ETA: 1s - loss: 0.0085"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\tmain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
